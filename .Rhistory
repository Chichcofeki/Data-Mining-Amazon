res.pca$ind$coord
res.pca$ind$coord[,c(1,2)]
res.pca$ind$
res.pca$ind$cos2
res.pca$ind$contrib
res.pca$ind$contrib[,c(1,2)]
res.pca$var$ind
sort(res.pca$ind$coord[,c(1,2)])
sort(res.pca$ind$coord[,c(1)])
res.pca$ind$contrib[,c(1)]
sort(res.pca$ind$contrib[,c(1)])
sort(res.pca$ind$contrib[,c(1)])
dimdesc(res.pca);
plot.PCA(res.pca,axes=c(1,2),choix=c("var"))
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"))
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = )
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = T)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = res.pca)
?plot.PCA
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = res.pca$ind)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = res.pca$ind$coord)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = res.pca$ind$coord[,1])
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = T)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = TRUE)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse = res)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"),ellipse)
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"))
sort(res.pca$ind$coord[,c(1)]);
sort(res.pca$ind$contrib[,c(1)]);
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"));
sort(res.pca$ind$coord[,c(1)]);
sort(res.pca$ind$contrib[,c(1)]);
sort(res.pca$ind$contrib[,c(2)]);
sort(res.pca$ind$coord[,c(2)]);
sort(res.pca$ind$contrib[,c(2)]);
?sort()
sort(res.pca$ind$contrib[,c(2)],decreasing =FALSE);
sort(res.pca$ind$contrib[,c(2)],decreasing =TRUE);
sort(res.pca$ind$coord[,c(1)],decreasing=TRUE);
sort(res.pca$ind$coord[,c(2)],decreasing=TRUE);
sort(res.pca$ind$contrib[,c(2)],decreasing =TRUE);
sort(res.pca$ind$coord[,c(2)],decreasing=TRUE);
sort(res.pca$ind$contrib[,c(2)],decreasing =TRUE);
sort(res.pca$ind$contrib[,c(1)],decreasing =TRUE);
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"));
plot.PCA(res.pca,axes=c(1,2),choix=c("var"));
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"));
output: word_document
plot.PCA(res.pca,axes=c(1,2),choix=c("ind"));
sort(res.pca$ind$contrib[,c(1)],decreasing =TRUE);
sort(res.pca$ind$contrib[,c(1)],decreasing =TRUE);
res.pca = PCA(data,var.sup=8, scale.unit=TRUE, ncp=5, graph=F);
res.pca = PCA(data,quanti.sup=8, scale.unit=TRUE, ncp=5, graph=F);
res.pca$eig
dimdesc(res.pca)
res.pca = PCA(data,scale.unit=TRUE, ncp=5, graph=F,quanti.sup=8);
res.pca$eig
dimdesc(res.pca)
res.pca$var
res.pca$eig
res.pca$eig
plot.PCA(res.pca,axes=c(1,2),choix=c("var"));
res.pca$var
dimdesc(res.pca)
library(FactoMineR);
data=read.csv2(file.choose(),row.names=1,dec=",");
res.pca = PCA(data,scale.unit=TRUE, ncp=5, graph=F,quanti.sup=8);
res.pca$eig
dimdesc(res.pca)
res.pca$var
plot.PCA(res.pca,axes=c(1,2),choix=c("var"));
sort(res.pca$ind$contrib[,c(1)],decreasing =TRUE);
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=8)
res.pca = PCA(data,scale.unit=TRUE, ncp=5, graph=F,quanti.sup=8);
plot.PCA(res.pca, axes=c(1, 2), choix="ind", habillage=8)
plot.PCA(res.pca, axes=c(1, 2), choix="ind")
plot(data[,"score"])
plot(data[,"shot"])
install.packages("twitteR", "RCurl", "RJSONIO", "stringr")
install.packages("twitteR")
install.packages("RCurl")
install.packages("RJSONIO")
install.packages("stringr")
# Declare Twitter API Credentials
api_key <- "3K6VlrStUptSZ0EAJpexIpF0z" # From dev.twitter.com
api_secret <- "n5iaFmbb0wSeqW55Xgq8WcOifYpwgKnXDBDJRw9tvPkPxHwSOP" # From dev.twitter.com
token <- "764477638933184513-5wmPDIzu5VpvReDvkxCjYtvtsDtj3PC" # From dev.twitter.com
token_secret <- "cmd0SMEot9IvqDVGF5Vl9SSLSbqwSVm2A1rkdUHrkUzY3" # From dev.twitter.com
# Create Twitter Connection
setup_twitter_oauth(api_key, api_secret, token, token_secret)
library(twitteR)
library(RCurl)
library(RJSONIO)
library(stringr)
api_key <- "3K6VlrStUptSZ0EAJpexIpF0z" # From dev.twitter.com
api_secret <- "n5iaFmbb0wSeqW55Xgq8WcOifYpwgKnXDBDJRw9tvPkPxHwSOP" # From dev.twitter.com
token <- "764477638933184513-5wmPDIzu5VpvReDvkxCjYtvtsDtj3PC" # From dev.twitter.com
token_secret <- "cmd0SMEot9IvqDVGF5Vl9SSLSbqwSVm2A1rkdUHrkUzY3" # From dev.twitter.com
setup_twitter_oauth(api_key, api_secret, token, token_secret)
tweets <- searchTwitter("Obamacare OR ACA OR 'Affordable Care Act' OR #ACA", n=100, lang="en", since="2014-08-20")
tweets.df <- twListToDF(tweets)
View(tweets.df)
install.packages("wordcloud")
install.packages("tm")
library("twitteR")
library("wordcloud")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library("twitteR")
library("wordcloud")
install.packages("wordcloud")
library("wordcloud")
library("tm")
install.packages("NLP")
install.packages("NLP")
install.packages("tm")
library("tm")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
library("wordcloud")
library("tm")
consumer_key <- "3K6VlrStUptSZ0EAJpexIpF0z" # From dev.twitter.com
consumer_secret <- "n5iaFmbb0wSeqW55Xgq8WcOifYpwgKnXDBDJRw9tvPkPxHwSOP" # From dev.twitter.com
access_token <- "764477638933184513-5wmPDIzu5VpvReDvkxCjYtvtsDtj3PC" # From dev.twitter.com
access_secret <- "cmd0SMEot9IvqDVGF5Vl9SSLSbqwSVm2A1rkdUHrkUzY3" # From dev.twitter.com
setup_twitter_oauth(consumer_key,
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
r_stats <- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
library("twitteR")
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
#the cainfo parameter is necessary only on Windows
r_stats <- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
r_stats <- searchTwitter("#Rstats", n=1500, cainfo="cacert.pem")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
r_stats <- searchTwitter("#Rstats", n=1500)
length(r_stats)
r_stats_text <- sapply(r_stats, function(x) x$getText())
r_stats_text_corpus <- Corpus(VectorSource(r_stats_text))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, content_transformer(tolower))
r_stats_text_corpus <- tm_map(r_stats_text_corpus, removePunctuation)
r_stats_text_corpus <- tm_map(r_stats_text_corpus, function(x)removeWords(x,stopwords()))
wordcloud(r_stats_text_corpus)
library(tm)
library('wordcloud')
library("tm")
library("twitteR")
rm(data)
rm(res.pca)
consumer_key <- '3K6VlrStUptSZ0EAJpexIpF0z'
consumer_secret <- 'n5iaFmbb0wSeqW55Xgq8WcOifYpwgKnXDBDJRw9tvPkPxHwSOP'
access_token <- '764477638933184513-5wmPDIzu5VpvReDvkxCjYtvtsDtj3PC'
access_secret <- 'cmd0SMEot9IvqDVGF5Vl9SSLSbqwSVm2A1rkdUHrkUzY3'
setup_twitter_oauth(consumer_key,consumer_secret,access_token,access_secret)
tweets <- userTimeline("RDataMining",n=3200)
tweets.df <- twListToDF(tweets)
strwrap( tweets.df$text[190],60)
writeLines( strwrap( tweets.df$text[190] ) )
writeLines( strwrap( tweets.df$text[190],60 ) )
writeLines( strwrap( tweets.df$text[190] ) )
writeLines( strwrap( tweets.df$text[190],60 ) )
Vector.source=VectorSource(tweets.df$text)
names(Vector.source)
Vectord.source$content[2]
vector.source
Vector.source
tweets.df <- twListToDF(tweets)
fix(tweets.df)
View(tweets.df)
names(tweets.df)
labels(tweets.df)
tweets.df$text[2]
Vector.source
names(Vector.source)
Vectord.source$content[2]
Vector.source$content[2]
tw.corpus = Corpus (Vector.source)
as.character(tw.co)
as.character(tw.corpus)
as.character(tw.corpus[[2]])
library(wordcloud)
tw.corpus=tm_map(tw.corpus,content_transformer(removeURL))
tw.corpus=tm_map(tw.corpus,content_transformer(removeURL))
tw.corpus=tm_map(tw.corpus,content_transformer(tolower))
tw.corpus=tm_map(tw.corpus,content_transformer(removeURL))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
tw.corpus=tm_map(tw.corpus,content_transformer(removeURL))
tw.corpuse
tw.corpus
tw.corpus[2]
tw.corpus[[1]]
as.character(tw.corpus[[1]])
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*","",x)
tw.corpus=tm_map(tw.corpus,content_transformer(removeNumPunct))
as.character(tw.corpus[[1]])
stopwords(as.character(tw.corpus[[1]]))
stopwords('English')
myStopwords.anglais<-c(stopwords('english'),"use","see","used","via","amp")
length(myStopwords.anglais)
myStopwords.anglais <- setdiff(myStopwords.anglais,c("r","big"))
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
as.matrix(tdm)
as.matrix(tdm[idx,21:30])
idx = which(dimnames(tdm)$Terms =="r")
inspect(tdm[idx + (0:5),101:110])
idx = which (dimnames(tdm)$Terms %in% c("r","data","mining"))
as.matrix(tdm[idx,21:30])
(freq.terms = findFreqTerms(tdm,lowfre=20))
length(myStopwords.anglais)
tw.corpus[[455]]
tw.corpus[[45]]
tw.corpus[[45]]$content
tw.corpus = tm_map(tw.corpus,removeWords,myStopwords.anglais)
tw.corpus[[45]]$content
tw.corpus = tm_map(tw.corpus,removeWords,stripWhitespace)
tw.corpus = tm_map(tw.corpus,stripWhitespace)
tw.corpus[[45]]$content
tw.corpus.copy = tw.corpus
tw.corpus.copy
tw.corpus.copy$[[190]]
tw.corpus.copy$[[19]]
tw.corpus.copy[[19]]$content
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument)
tw.corpus.copy[[19]]$content
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument,dictionary=tw.corpus)
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument2,dictionary=tw.corpus)
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""] # x ne mantient que ses éléments différents de du vide ("")
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ") # concatener les éléments de x
PlainTextDocument(stripWhitespace(x))
}
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument2,dictionary=tw.corpus)
tw.corpus.copy = tm_map(tw.corpus.copy,stemCompletion2,dictionary=tw.corpus)
tw.corpus.copy[[19]]$content
tw.corpus.copy[[19]]$content
tw.corpus.copy[[1]]$content
writeLines(strwrap(tw.corpus.copy[[190]]$content, 60))
writeLines(strwrap(tw.corpus.copy[[5]]$content, 60))
writeLines(strwrap(tw.corpus.copy[[1]]$content, 60))
monCorpus_RDM.Copy <- Corpus(VectorSource(tw.corpus.copy))
writeLines(strwrap(tw.corpus.copy[[1]]$content, 60))
writeLines(strwrap(tw.corpus.copy[[1]]$content, 60))
wordFreq <- function(corpus, word)
{
results <- lapply(corpus,
function(x) { grep(as.character(x), pattern=paste0("\\<",word)) })
sum(unlist(results))
}
n.miner <- wordFreq(monCorpus_RDM.Copy, "miner")
n.mining <- wordFreq(monCorpus_RDM.Copy, "mining")
cat(n.miner, n.mining)
tdm = TermDocumentMatrix(tw.corpus.copy,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
idx = which(dimnames(tdm)$Terms =="r")
inspect(tdm[idx + (0:5),101:110])
idx = which (dimnames(tdm)$Terms %in% c("r","data","mining"))
as.matrix(tdm[idx,21:30])
(freq.terms = findFreqTerms(tdm,lowfre=20))
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
idx = which(dimnames(tdm)$Terms =="r")
inspect(tdm[idx + (0:5),101:110])
idx = which (dimnames(tdm)$Terms %in% c("r","data","mining"))
as.matrix(tdm[idx,21:30])
(freq.terms = findFreqTerms(tdm,lowfre=20))
(term.freq <- subset(term.freq, term.freq >= 20))
(freq.terms = findFreqTerms(tdm,lowfre=20))
(freq.terms <- subset(freq.terms, term.freq >= 20))
(freq.terms <- subset(freq.terms, freq.terms >= 20))
df <- data.frame(term = names(term.freq), freq = term.freq)
df <- data.frame(term = names(freq.terms), freq = freq.terms)
library(ggplot2)
df <- data.frame(term = names(freq.terms), freq = freq.terms)
df <- data.frame(terms = names(freq.terms), freq = freq.terms)
df <- data.frame(terms = names(freq.terms), freq = freq.terms)
df <- data.frame(freq = freq.terms)
terms()library(ggplot2)
library(ggplot2)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
labels(dimnames(tdm))
df <- data.frame(Terms = names(freq.terms), freq = freq.terms)
labels(dimnames(tdm))
df <- data.frame(term = names(freq.terms), freq = freq.terms)
names(freq.terms)
(freq.terms = findFreqTerms(tdm,lowfre=20))
(freq.terms <- subset(freq.terms, freq.terms >= 20))
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(term.freq <- subset(term.freq, term.freq >= 20))
names(freq.terms)
names(tdm)
tw.corpus.copy = tw.corpus
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument)
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""] # x ne mantient que ses éléments différents de du vide ("")
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ") # concatener les éléments de x
PlainTextDocument(stripWhitespace(x))
}
tw.corpus.copy = tm_map(tw.corpus.copy,stemCompletion2,dictionary=tw.corpus)
tw.corpus.copy[[1]]$content
tw.corpus.copy = tw.corpus
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument)
tw.corpus.copy = tm_map(tw.corpus.copy,stemCompletion2,dictionary=tw.corpus)
tw.corpus.copy = tw.corpus
tw.corpus.copy = tm_map(tw.corpus.copy,stemDocument)
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""] # x ne mantient que ses éléments différents de du vide ("")
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ") # concatener les éléments de x
PlainTextDocument(stripWhitespace(x))
}
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""] # x ne mantient que ses éléments différents de du vide ("")
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ") # concatener les éléments de x
PlainTextDocument(stripWhitespace(x))
}
tw.corpus.copy = lapply(tw.corpus.copy,stemCompletion2,dictionary=tw.corpus)
tw.corpus.copy[[1]]$content
writeLines(strwrap(tw.corpus.copy[[1]]$content, 60))
monCorpus_RDM.Copy <- Corpus(VectorSource(tw.corpus.copy))
writeLines(strwrap(tw.corpus.copy[[1]]$content, 60))
writeLines(strwrap(tw.corpus.copy[[1]]$content, 60))
wordFreq <- function(corpus, word)
{
results <- lapply(corpus,
function(x) { grep(as.character(x), pattern=paste0("\\<",word)) })
sum(unlist(results))
}
n.miner <- wordFreq(monCorpus_RDM.Copy, "miner")
n.mining <- wordFreq(monCorpus_RDM.Copy, "mining")
cat(n.miner, n.mining)
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
idx = which(dimnames(tdm)$Terms =="r")
inspect(tdm[idx + (0:5),101:110])
idx = which (dimnames(tdm)$Terms %in% c("r","data","mining"))
as.matrix(tdm[idx,21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(term.freq <- subset(term.freq, term.freq >= 20))
(freq.terms <- subset(freq.terms, freq.terms >= 20))
names((term.freq <- subset(term.freq, term.freq >= 20)))
df <- data.frame(term = names(freq.terms), freq = freq.terms)
names(freq.terms)
freq.terms
levels(freq.terms)
labels(freq.terms)
freq.terms
names(freq.terms)
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
as.matrix(tdm[idx,21:30])
names(freq.terms)
idx = which (dimnames(tdm)$Terms %in% c("r","data","mining"))
idx
labels(dimnames(tdm))
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
idx = which(dimnames(tdm)$Terms =="r")
inspect(tdm[idx + (0:5),101:110])
idx = which (dimnames(tdm)$Terms %in% c("r","data","mining"))
as.matrix(tdm[idx,21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(term.freq <- subset(freq.terms, freq.terms >= 20))
labels(freq.terms)
df <- data.frame(term = freq.terms, freq = freq.terms)
names(freq.terms)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
labels(dimnames(tdm))
df <- data.frame(term = names(term.freq), freq = freq.terms)
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(term.freq <- subset(freq.terms, freq.terms >= 20))
labels(freq.terms)
df <- data.frame(term = names(term.freq), freq = freq.terms)
findFreqTerms(tdm)
findFreqTerms(tdm)
m=findFreqTerms(tdm)
as.matrix(m)
as.matrix(m)
sort(as.matrix(m))
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(term.freq <- subset(freq.terms, freq.terms >= 20))
labels(freq.terms)
df <- data.frame(term = names(term.freq), freq = freq.terms)
names(freq.terms)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
labels(dimnames(tdm))
as.matrix(tdm)
as.matrix(tdm[idx,21:30])
m=findFreqTerms(tdm)
findFreqTerms(tdm)
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(freq.terms <- findFreqTerms(tdm, lowfreq >= 20))
(freq.terms <- findFreqTerms(tdm, lowfreq => 20))
(freq.terms <- findFreqTerms(tdm, lowfreq > 20))
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
freq(tdm)
frequency(tdm)
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(freq.terms <- subset(freq.terms, freq.terms >= 20))
labels(freq.terms)
df <- data.frame(term = names(term.freq), freq = freq.terms)
df <- data.frame(term = names(freq.terms), freq = freq.terms)
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
(freq.terms <- subset(tdm, freq.terms >= 20))
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
as.matrix(tdm[idx,21:30])
(freq.terms <- findFreqTerms(as.matrix(tdm), lowfreq = 20))
(freq.terms <- findFreqTerms(freq, lowfreq = 20))
as.matrix(tdm[idx,21:30])
mat=as.matrix(tdm[idx,21:30])
names(mat)
mat=as.matrix(tdm[idx,21:30])
(freq.terms <- findFreqTerms(freq, lowfreq = 20))
(freq.terms <- subset(freq.terms, freq.terms >= 20))
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(freq.terms <- subset(freq.terms, freq.terms >= 20))
labels(freq.terms)
names(freq.terms)
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
tdm$i
tdm$j
tdm$v
tdm$dimnames
tdm$Terms
tdm$dimnames$Terms
(freq.terms <- findFreqTerms(tdm$dimnames$Terms, lowfreq = 20))
attach(tdm)
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
(term.freq <- subset(term.freq, term.freq >= 20))
(term.freq <- subset(tdm$dimnames$term.freq, tdm$dimnames$term.freq >= 20))
(term.freq <- subset(tdm$dimnames$term.freq, tdm$dimnames$term.freq >= 20))
names(freq.terms)
df <- data.frame(term = names(freq.terms), freq = freq.terms)
mat=as.matrix(tdm[idx,21:30])
detach(tdm)
tdm = TermDocumentMatrix(tw.corpus,control=list(wordLengths = c(1,Inf)))
labels(dimnames(tdm))
mat=as.matrix(tdm)
mat
View(mat)
names(mat)
(freq.terms <- findFreqTerms(mat, lowfreq = 20))
freq.terms <- findFreqTerms(tdm, lowfreq = 20)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing=TRUE)
head(v, N)
head(v, 10)
names(v)
df <- data.frame(term = names(v), freq = v)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
freq.terms <- findFreqTerms(tdm, lowfreq = 20)
df <- data.frame(term = freq.terms, freq = freq.terms)
df <- data.frame(term = freq.terms, freq = v)
df <- data.frame(term = freq.terms, freq = v[freq.terms])
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
sort(v)
df <- data.frame(term = freq.terms, freq = v[freq.terms])
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
x=sort(v[freq.terms])
df <- data.frame(term = freq.terms, freq = v[freq.terms])
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
names(x)
df <- data.frame(term = names(x), freq = x)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
df <- data.frame(term = freq.terms, freq = v[freq.term],sort=T)
ggplot(df, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
ggplot(df,sort=T, aes(x = term, y = freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
ggplot(df,sort=T, aes(reorder(term, freq),freq)) + geom_bar(stat = "identity") + xlab("Terms") + ylab("Count") + coord_flip()
freq.terms
v <- sort(rowSums(m), decreasing=TRUE)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing=TRUE)
head(v, 10)
library(wordcloud)
cloud(v)
wordcloud(words=names(v))
wordcloud(words=names(v),freq=v)
wordcloud(words=names(v),freq=v)
install.packages(Rmarkdown)
install.packages("rmarkdown")
knitr::opts_chunk$set(echo = TRUE)
install.packages(devtools)
package(devtools)
install.packages(devtools)
install.packages("devtools"")
library(devtools)
install.packages("devtools")
install.packages("devtools")
install.packages("git")
install.packages("git")
rm(*)
setwd("//qlsrv/ft510263/Bureau/GitHub/Data-Mining-Amazon")
shiny::runApp('//qlsrv/ft510263/Bureau/GitHub/Data-Mining-Amazon')
shiny::runApp('//qlsrv/ft510263/Bureau/GitHub/Data-Mining-Amazon')
install.packages("tm")
install.packages("ggplot2")
install.packages("wordcloud")
shiny::runApp('//qlsrv/ft510263/Bureau/GitHub/Data-Mining-Amazon')
library(tm)
install.packages("slam")
install.packages("slam")
