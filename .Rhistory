data=read.csv2(file.choose(),sep=";",dec=",")
summary(data)
data=read.csv2(file.choose(),sep=";",dec=",")
summary(data)
View(data)
data$nom.
nom
nom=data$nom.
nom
?sub
nom=sub(nom,'-',' ');
?sub
nom=sub(nom,"-"," ");
nom=data$nom.
nom=sub(nom,"-"," ");
nom=data$nom.
nom[,]
nom[]
nom[]=sub(nom[],"-"," ");
nom[]
nom=data$nom.
for (nom in str) {
print(str);
}
nom=data$nom.
for (nom in str) {
print(str);
}
nom=data$nom.
nom=data$nom.
nom=data$nom.
data$nom.
nom=data$nom.
for (nom in str) {
print(str);
}
nom=data$nom.
View(data)
fix(data)
library(rcmdr)
install.packages(Rcmdr)
"Rcmdr"
library('Rcmdr')
library('Rcmdr')
library(Rcmdr)
install.packages('Rcmdr')
library(Rcmdr)
data=getSentiments("amazon")
setwd("C:/Users/extra/OneDrive/Etudes/Projet DATA MINING - Option/Data-Mining-Amazon")
data=getSentiments("amazon")
source("sentiment_analysis.r")
data=getSentiments("amazon")
data=getSentiments('amazon')
library(pracma)
library(plyr)
library(stringr)
library(e1071)
df=read.table(paste('avis/amazon.txt',sep=""), sep='\t')
source('fonction/util.R')
source('fonction/sentiment.R')
data <- total.results
ind=sample(2, nrow(data),replace = T, prob=c(0.7,0.3))
indice=sample(2,lendth(data),replace = T, prob=c(0.7,0.3))
indice=sample(2,length(data),replace = T, prob=c(0.7,0.3))
ensemble_apprentissage=data[indice==1,]
ensemble_test=data[ind==2,]
?naiveBayes
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
library(pracma)
library(plyr)
library(stringr)
library(e1071)
df=read.table(paste('avis/amazon.txt',sep=""), sep='\t')
source('fonction/util.R')
source('fonction/sentiment.R')
data <- total.results
prediction <- predict(NaiveBayesClassifier, data)
data$prediction=prediction
conf.matrix <- table(data[,5], data[,4], dnn=list('predicted','actual'))
runApp()
as.character(corpus.amazon[[1]])
library(tm)
library(tm)
library(ggplot2)
library(wordcloud)
filepath="amazon"
amazon=read.table(paste('avis/',filepath,'.txt',sep=""), sep='\t', col.names = c("text","avis"))
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
vector.amazon=VectorSource(amazon$text);
corpus.amazon=Corpus(vector.amazon)
corpus.amazon=tm_map(corpus.amazon, content_transformer(tolower))
corpus.amazon=tm_map(corpus.amazon, content_transformer(removeNumPunct))
myStopwords <- c(stopwords('english'), "use", "see", "used", "via", "amp", "us", "go")
corpus.amazon=tm_map(corpus.amazon, removeWords,myStopwords)
corpus.amazon=tm_map(corpus.amazon, stripWhitespace)
corpus.amazon=tm_map(corpus.amazon,stemDocument)
vector.amazon=VectorSource(amazon$text);
corpus.amazon=Corpus(vector.amazon)
corpus.amazon=tm_map(corpus.amazon,stemDocument)
corpus.amazon=tm_map(corpus.amazon, stripWhitespace)
corpus.amazon=tm_map(corpus.amazon,stemDocument)
corpus.amazon=tm_map(corpus.amazon, content_transformer(removeNumPunct))
corpus.amazon=tm_map(corpus.amazon, content_transformer(tolower))
corpus.amazon=tm_map(corpus.amazon,stemDocument)
vector.amazon=VectorSource(amazon$text);
corpus.amazon=Corpus(vector.amazon)
corpus <- tm_map(corpus, removePunctuation)
vector.amazon=VectorSource(amazon$text);
corpus=Corpus(vector.amazon)
filepath="amazon"
amazon=read.table(paste('avis/',filepath,'.txt',sep=""), sep='\t', col.names = c("text","avis"))
vector.amazon=VectorSource(amazon$text);
corpus=Corpus(vector.amazon)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, PlainTextDocument)  # needs to come before stemming
corpus <- tm_map(corpus, stemDocument, "english")
runApp()
runApp()
runApp()
runApp()
filepath="amazon"
amazon=read.table(paste('avis/',filepath,'.txt',sep=""), sep='\t', col.names = c("text","avis"))
vector.amazon=VectorSource(amazon$text);
corpus=Corpus(vector.amazon)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, PlainTextDocument)  # Besoin de le retourner en PlainTextDocumet and le stemming
corpus <- tm_map(corpus, stemDocument, "english")
tdm = TermDocumentMatrix(corpus)
tdm = TermDocumentMatrix(corpus$content)
library(tm)
library(ggplot2)
library(wordcloud)
tdm = TermDocumentMatrix(corpus)
vector.amazon=VectorSource(amazon$text);
corpus.txt=Corpus(vector.amazon)
corpus.txt <- tm_map(corpus.txt, removePunctuation)
corpus.txt <- tm_map(corpus.txt, removeNumbers)
corpus.txt <- tm_map(corpus.txt, tolower)
corpus.txt <- tm_map(corpus.txt, removeWords, stopwords("english"))
corpus.txt <- tm_map(corpus.txt, PlainTextDocument)  # Besoin de le retourner en PlainTextDocumet and le stemming
corpus.txt <- tm_map(corpus.txt, stemDocument, "english")
tdm = TermDocumentMatrix(corpus.txt)
vector.amazon=VectorSource(amazon$text);
library(tm)
library(ggplot2)
library(wordcloud)
filepath="amazon"
amazon=read.table(paste('avis/',filepath,'.txt',sep=""), sep='\t', col.names = c("text","avis"))
vector.amazon=VectorSource(amazon$text);
corpus.txt=Corpus(vector.amazon)
corpus.txt <- tm_map(corpus.txt, removePunctuation)
corpus.txt <- tm_map(corpus.txt, removeNumbers)
corpus.txt <- tm_map(corpus.txt, tolower)
corpus.txt <- tm_map(corpus.txt, removeWords, stopwords("english"))
corpus.txt <- tm_map(corpus.txt, PlainTextDocument)  # Besoin de le retourner en PlainTextDocumet and le stemming
corpus.txt <- tm_map(corpus.txt, stemDocument, "english")
tdm = TermDocumentMatrix(corpus.txt)
filepath="amazon"
amazon=read.table(paste('avis/',filepath,'.txt',sep=""), sep='\t', col.names = c("text","avis"))
#============ Création du corpus ====================================
vector.amazon=VectorSource(amazon$text);
corpus.txt=Corpus(vector.amazon)
#============ Nettoyage ====================================
corpus.txt <- tm_map(corpus.txt, removePunctuation)
corpus.txt <- tm_map(corpus.txt, removeNumbers)
corpus.txt <- tm_map(corpus.txt, tolower)
corpus.txt <- tm_map(corpus.txt, removeWords, stopwords("english"))
#corpus.txt <- tm_map(corpus.txt, PlainTextDocument)  # Besoin de le retourner en PlainTextDocumet and le stemming
corpus.txt <- tm_map(corpus.txt, stemDocument, "english")
tdm = TermDocumentMatrix(corpus.txt)
corpus.txt <- tm_map(corpus.txt, removePunctuation)
vector.amazon=VectorSource(amazon$text);
corpus.txt=Corpus(vector.amazon)
corpus.txt <- tm_map(corpus.txt, removePunctuation)
vector.amazon=VectorSource(amazon$text);
corpus=Corpus(vector.amazon)
filepath="amazon"
amazon=read.table(paste('avis/',filepath,'.txt',sep=""), sep='\t', col.names = c("text","avis"))
#============ Création du corpus ====================================
vector.amazon=VectorSource(amazon$text);
corpus=Corpus(vector.amazon)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, PlainTextDocument)  # Besoin de le retourner en PlainTextDocumet and le stemming
tdm = TermDocumentMatrix(corpus)
corpus=Corpus(vector.amazon)
vector.amazon=VectorSource(amazon$text);
corpus=Corpus(vector.amazon)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, PlainTextDocument)  # Besoin de le retourner en PlainTextDocumet and le stemming
corpus <- tm_map(corpus, stemDocument, "english")
as.character(corpus[[1]])
as.character(corpus[[1,1]])
as.character(corpus[[1]])
as.character(corpus[[1]])
as.character(corpus[[2]])
as.character(corpus$content)
as.character(corpus$content[372])
as.character(corpus$content[,372])
as.character(corpus$content[372,])
as.character(corpus$content)
install.packages(c("backports", "BH", "car", "chron", "data.table", "DBI", "digest", "e1071", "FactoMineR", "Hmisc", "htmlTable", "jsonlite", "knitr", "leaps", "lmtest", "mvtnorm", "openssl", "pbkrtest", "Rcmdr", "Rcpp", "RcppEigen", "rgl", "rmarkdown", "rprojroot", "scatterplot3d", "SparseM", "stringi", "stringr", "survival", "TH.data", "yaml"))
install.packages("shiny")
library(shiny)
install.packages("shiny")
install.packages("shiny")
